#!/usr/bin/env python3
"""
Comprehensive Functional Quality Testing for Klerno Labs
Tests all core business functionality with performance metrics
"""

import os
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

import json
import time
from datetime import datetime, timezone


def test_transaction_processing_pipeline():
    """Test complete transaction processing pipeline"""
    print("üí∞ Testing Transaction Processing Pipeline...")
    
    start_time = time.time()
    
    try:
        from app.analytics import AdvancedAnalytics
        from app.compliance import AddressBook, tag_categories
        from app.guardian import score_risk
        from app.integrations.xrp import xrpl_json_to_transactions

        # Sample XRPL transaction data
        sample_xrpl_data = [
            {
                "tx": {
                    "hash": "A1B2C3D4E5F6789012345678901234567890ABCDEF1234567890ABCDEF123456",
                    "date": 1698764400,  # Unix timestamp relative to XRPL epoch
                    "Account": "rN7n7otQDd6FczFgLdSqtcsAUxDkw6fzRH",
                    "Destination": "rLNaPoKeeBjZe2qs6x52yVPZpZ8td4dc6w",
                    "Amount": "50000000",  # 50 XRP in drops
                    "Fee": "12",  # Fee in drops
                }
            },
            {
                "tx": {
                    "hash": "B2C3D4E5F6789012345678901234567890ABCDEF1234567890ABCDEF1234567A",
                    "date": 1698764500,
                    "Account": "rLNaPoKeeBjZe2qs6x52yVPZpZ8td4dc6w",
                    "Destination": "rN7n7otQDd6FczFgLdSqtcsAUxDkw6fzRH",
                    "Amount": "1000000",  # 1 XRP in drops
                    "Fee": "12",
                }
            }
        ]
        
        # Test 1: XRPL JSON to Transaction conversion
        account = "rN7n7otQDd6FczFgLdSqtcsAUxDkw6fzRH"
        transactions = xrpl_json_to_transactions(account, sample_xrpl_data)
        print(f"  ‚úÖ Converted {len(transactions)} XRPL transactions")
        print(f"     Transaction 1: {transactions[0].amount} XRP, Fee: {transactions[0].fee}")
        
        # Test 2: Compliance tagging
        address_book = AddressBook({"rN7n7otQDd6FczFgLdSqtcsAUxDkw6fzRH"})
        for i, tx in enumerate(transactions):
            tags = tag_categories(tx, address_book)
            print(f"  ‚úÖ Transaction {i+1} tagged with {len(tags)} categories")
            
        # Test 3: Risk scoring
        for i, tx in enumerate(transactions):
            risk_score, reasons = score_risk(tx)
            print(f"  ‚úÖ Transaction {i+1} risk score: {risk_score:.3f}, reasons: {len(reasons)}")
            
        # Test 4: Analytics
        analytics = AdvancedAnalytics()
        print("  ‚úÖ Analytics engine initialized")
        
        processing_time = time.time() - start_time
        print(f"  ‚ö° Pipeline completed in {processing_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"  ‚ùå Pipeline failed after {processing_time:.3f} seconds: {e}")
        return False

def test_authentication_security():
    """Test authentication and security features"""
    print("\nüîê Testing Authentication & Security...")
    
    start_time = time.time()
    
    try:
        from app.security import EnterpriseSecurityMiddleware
        from app.security_session import hash_pw, issue_jwt, verify_pw

        # Test password security
        test_passwords = [
            "simple123",
            "Complex@Password123!",
            "VeryComplexPassword@2024#WithSpecialChars",
        ]
        
        for pwd in test_passwords:
            hashed = hash_pw(pwd)
            verified = verify_pw(pwd, hashed)
            if not verified:
                print(f"  ‚ùå Password verification failed for: {pwd}")
                return False
        
        print(f"  ‚úÖ Password hashing verified for {len(test_passwords)} passwords")
        
        # Test JWT tokens
        test_users = [
            {"id": 1, "email": "admin@klerno.com", "role": "admin"},
            {"id": 2, "email": "user@example.com", "role": "user"},
            {"id": 3, "email": "manager@company.com", "role": "manager"},
        ]
        
        tokens = []
        for user in test_users:
            token = issue_jwt(user["id"], user["email"], user["role"])
            tokens.append(token)
            
        print(f"  ‚úÖ Generated {len(tokens)} JWT tokens")
        
        # Test security middleware
        try:
            middleware = EnterpriseSecurityMiddleware()
            print("  ‚úÖ Enterprise security middleware initialized")
        except Exception as middleware_error:
            print(f"  ‚ö†Ô∏è Security middleware issue: {middleware_error}")
        
        auth_time = time.time() - start_time
        print(f"  ‚ö° Authentication tests completed in {auth_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        auth_time = time.time() - start_time
        print(f"  ‚ùå Authentication failed after {auth_time:.3f} seconds: {e}")
        return False

def test_data_models_validation():
    """Test data models and validation"""
    print("\nüìä Testing Data Models & Validation...")
    
    start_time = time.time()
    
    try:
        from app.models import AccountStatus, Transaction, UserRole

        # Test enums
        print(f"  ‚úÖ UserRole: {len(list(UserRole))} roles available")
        print(f"  ‚úÖ AccountStatus: {len(list(AccountStatus))} statuses available")
        
        # Test transaction creation with various data
        test_transactions = []
        
        # Valid transaction
        try:
            tx1 = Transaction(
                tx_id="test_tx_1",
                timestamp=datetime.now(timezone.utc),
                chain="XRP",
                from_addr="rTestSender123",
                to_addr="rTestReceiver456",
                amount=100.0,
                symbol="XRP",
                direction="out",
                memo="Test transaction",
                fee=0.12
            )
            test_transactions.append(tx1)
            print(f"  ‚úÖ Created transaction: {tx1.tx_id}")
        except Exception as tx_error:
            print(f"  ‚ö†Ô∏è Transaction creation issue: {tx_error}")
        
        # Test with edge cases
        edge_cases = [
            {"amount": 0.000001, "description": "micro amount"},
            {"amount": 1000000.0, "description": "large amount"},
            {"fee": 0.0, "description": "zero fee"},
        ]
        
        for i, case in enumerate(edge_cases):
            try:
                tx = Transaction(
                    tx_id=f"edge_tx_{i}",
                    timestamp=datetime.now(timezone.utc),
                    chain="XRP",
                    from_addr=f"rEdgeCase{i}",
                    to_addr=f"rEdgeTarget{i}",
                    amount=case["amount"],
                    symbol="XRP",
                    direction="out",
                    memo=f"Edge case: {case['description']}",
                    fee=case.get("fee", 0.12)
                )
                test_transactions.append(tx)
            except Exception as edge_error:
                print(f"  ‚ö†Ô∏è Edge case failed ({case['description']}): {edge_error}")
        
        print(f"  ‚úÖ Created {len(test_transactions)} test transactions")
        
        model_time = time.time() - start_time
        print(f"  ‚ö° Model validation completed in {model_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        model_time = time.time() - start_time
        print(f"  ‚ùå Model validation failed after {model_time:.3f} seconds: {e}")
        return False

def test_analytics_performance():
    """Test analytics performance with larger datasets"""
    print("\nüìà Testing Analytics Performance...")
    
    start_time = time.time()
    
    try:
        from app.analytics import AdvancedAnalytics, AnalyticsMetrics
        
        analytics = AdvancedAnalytics()
        
        # Test empty metrics (baseline)
        empty_metrics = analytics._empty_metrics()
        print(f"  ‚úÖ Empty metrics generated: {empty_metrics.total_transactions} transactions")
        
        # Test metrics generation (will use actual database if available)
        try:
            metrics = analytics.generate_comprehensive_metrics(days=7)
            print(f"  ‚úÖ Generated metrics for {metrics.total_transactions} transactions")
            print(f"     Total volume: ${metrics.total_volume:,.2f}")
            print(f"     Average risk: {metrics.avg_risk_score:.3f}")
            print(f"     Unique addresses: {metrics.unique_addresses}")
        except Exception as metrics_error:
            print(f"  ‚ö†Ô∏è Metrics generation (expected with empty DB): {metrics_error}")
        
        analytics_time = time.time() - start_time
        print(f"  ‚ö° Analytics performance test completed in {analytics_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        analytics_time = time.time() - start_time
        print(f"  ‚ùå Analytics performance failed after {analytics_time:.3f} seconds: {e}")
        return False

def test_compliance_engine():
    """Test compliance and tagging engine"""
    print("\n‚öñÔ∏è Testing Compliance Engine...")
    
    start_time = time.time()
    
    try:
        from app.compliance import AddressBook, tag_categories, tag_category

        # Create test address book
        known_addresses = {
            "rExchange1234567890",
            "rMyWallet1234567890", 
            "rTrustedPartner123",
        }
        address_book = AddressBook(known_addresses)
        
        # Test various transaction scenarios
        test_scenarios = [
            {
                "name": "High value transaction",
                "tx": {
                    "amount": 50000.0,
                    "from_addr": "rUnknownSender123",
                    "to_addr": "rMyWallet1234567890",
                    "memo": "Large payment for services"
                }
            },
            {
                "name": "Exchange transaction",
                "tx": {
                    "amount": 1000.0,
                    "from_addr": "rExchange1234567890",
                    "to_addr": "rMyWallet1234567890", 
                    "memo": "Withdrawal from exchange"
                }
            },
            {
                "name": "Small payment",
                "tx": {
                    "amount": 5.0,
                    "from_addr": "rMyWallet1234567890",
                    "to_addr": "rTrustedPartner123",
                    "memo": "Coffee payment"
                }
            }
        ]
        
        for scenario in test_scenarios:
            try:
                # Test multi-category tagging
                categories = tag_categories(scenario["tx"], address_book)
                primary_category = tag_category(scenario["tx"], address_book)
                
                print(f"  ‚úÖ {scenario['name']}: {len(categories)} categories, primary: {primary_category}")
            except Exception as scenario_error:
                print(f"  ‚ö†Ô∏è {scenario['name']} failed: {scenario_error}")
        
        compliance_time = time.time() - start_time
        print(f"  ‚ö° Compliance engine tested in {compliance_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        compliance_time = time.time() - start_time
        print(f"  ‚ùå Compliance engine failed after {compliance_time:.3f} seconds: {e}")
        return False

def test_risk_assessment():
    """Test risk assessment and guardian features"""
    print("\nüõ°Ô∏è Testing Risk Assessment...")
    
    start_time = time.time()
    
    try:
        from app.guardian import score_risk, score_risk_value

        # Test various risk scenarios
        risk_scenarios = [
            {
                "name": "Low risk - small amount",
                "tx": {"amount": 5.0, "memo": "Coffee payment"},
                "expected_range": (0.0, 0.3)
            },
            {
                "name": "Medium risk - larger amount",
                "tx": {"amount": 1000.0, "memo": "Business payment"},
                "expected_range": (0.2, 0.7)
            },
            {
                "name": "High risk - very large amount",
                "tx": {"amount": 100000.0, "memo": "Large transfer"},
                "expected_range": (0.6, 1.0)
            },
            {
                "name": "Suspicious - unusual pattern",
                "tx": {"amount": 50000.0, "memo": ""},
                "expected_range": (0.5, 1.0)
            }
        ]
        
        for scenario in risk_scenarios:
            try:
                risk_score, reasons = score_risk(scenario["tx"])
                risk_value = score_risk_value(scenario["tx"])
                
                min_risk, max_risk = scenario["expected_range"]
                in_range = min_risk <= risk_score <= max_risk
                
                status = "‚úÖ" if in_range else "‚ö†Ô∏è"
                print(f"  {status} {scenario['name']}: Risk {risk_score:.3f} ({len(reasons)} reasons)")
                
            except Exception as scenario_error:
                print(f"  ‚ùå {scenario['name']} failed: {scenario_error}")
        
        risk_time = time.time() - start_time
        print(f"  ‚ö° Risk assessment completed in {risk_time:.3f} seconds")
        
        return True
        
    except Exception as e:
        risk_time = time.time() - start_time
        print(f"  ‚ùå Risk assessment failed after {risk_time:.3f} seconds: {e}")
        return False

def main():
    """Run comprehensive functional testing"""
    print("üß™ Klerno Labs - Comprehensive Functional Quality Testing")
    print("=" * 70)
    print(f"Started at: {datetime.now()}")
    print()
    
    total_start_time = time.time()
    
    tests = [
        ("Transaction Processing Pipeline", test_transaction_processing_pipeline),
        ("Authentication & Security", test_authentication_security),
        ("Data Models & Validation", test_data_models_validation),
        ("Analytics Performance", test_analytics_performance),
        ("Compliance Engine", test_compliance_engine),
        ("Risk Assessment", test_risk_assessment),
    ]
    
    results = {}
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*25} {test_name} {'='*25}")
        test_start = time.time()
        
        try:
            success = test_func()
            test_duration = time.time() - test_start
            results[test_name] = {
                "success": success, 
                "error": None,
                "duration": test_duration
            }
            if success:
                passed += 1
                print(f"‚úÖ {test_name} PASSED in {test_duration:.3f}s")
            else:
                print(f"‚ùå {test_name} FAILED in {test_duration:.3f}s")
        except Exception as e:
            test_duration = time.time() - test_start
            results[test_name] = {
                "success": False, 
                "error": str(e),
                "duration": test_duration
            }
            print(f"‚ùå {test_name} ERROR in {test_duration:.3f}s: {e}")
    
    total_time = time.time() - total_start_time
    
    print("\n" + "="*70)
    print("üìä Comprehensive Functional Testing Summary")
    print("="*70)
    print(f"Total Tests: {total}")
    print(f"Passed: {passed}")
    print(f"Failed: {total - passed}")
    print(f"Success Rate: {(passed/total*100):.1f}%")
    print(f"Total Testing Time: {total_time:.3f} seconds")
    
    print("\nüìã Detailed Results:")
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result["success"] else "‚ùå FAIL"
        duration = result["duration"]
        print(f"{status} {test_name} ({duration:.3f}s)")
        if result["error"]:
            print(f"     Error: {result['error']}")
    
    # Performance analysis
    print("\n‚ö° Performance Analysis:")
    total_test_time = sum(r["duration"] for r in results.values())
    for test_name, result in results.items():
        percentage = (result["duration"] / total_test_time) * 100
        print(f"  {test_name}: {result['duration']:.3f}s ({percentage:.1f}%)")
    
    # Save comprehensive results
    test_results = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total": total,
            "passed": passed,
            "failed": total - passed,
            "success_rate": passed/total*100,
            "total_duration": total_time,
            "test_duration": total_test_time
        },
        "results": results,
        "performance_metrics": {
            "avg_test_time": total_test_time / total,
            "fastest_test": min(results.values(), key=lambda x: x["duration"]),
            "slowest_test": max(results.values(), key=lambda x: x["duration"])
        }
    }
    
    with open("comprehensive_test_results.json", "w") as f:
        json.dump(test_results, f, indent=2, default=str)
    
    print(f"\nüíæ Comprehensive results saved to comprehensive_test_results.json")
    print(f"üèÅ Testing completed at: {datetime.now()}")
    
    quality_score = passed / total
    if quality_score >= 0.99:
        print(f"\nüèÜ EXCELLENT QUALITY: {quality_score*100:.1f}% - Exceeds 99% standard!")
    elif quality_score >= 0.90:
        print(f"\n‚úÖ HIGH QUALITY: {quality_score*100:.1f}% - Meets production standards!")
    elif quality_score >= 0.80:
        print(f"\n‚ö†Ô∏è GOOD QUALITY: {quality_score*100:.1f}% - Minor improvements needed")
    else:
        print(f"\n‚ùå NEEDS IMPROVEMENT: {quality_score*100:.1f}% - Significant work required")
    
    return quality_score >= 0.9  # 90% success rate for production

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
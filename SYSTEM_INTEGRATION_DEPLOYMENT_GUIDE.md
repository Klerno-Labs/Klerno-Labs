# Comprehensive System Integration & Deployment Guide

## Overview

This guide provides complete instructions for integrating and deploying the enterprise-grade Klerno Labs system with all optimization components. The system now includes performance optimization, API documentation, security monitoring, error recovery, memory optimization, and comprehensive observability.

## System Architecture Overview

### Core Application Stack
- **FastAPI Application**: High-performance async web framework
- **Database Layer**: PostgreSQL with connection pooling and optimization
- **Caching Layer**: Multi-tier intelligent caching with Redis
- **Message Queue**: Async task processing with Celery/Redis
- **Monitoring Stack**: Comprehensive observability and alerting

### Optimization Components
1. **Performance Optimization**: Static analysis, async processing, intelligent caching
2. **Security Monitoring**: Real-time threat detection and automated response
3. **Error Recovery**: Predictive failure detection and automated recovery
4. **Memory Optimization**: Intelligent memory management and resource allocation
5. **Observability**: Distributed tracing, metrics, and monitoring dashboards

## Environment Setup

### Development Environment

```bash
# Environment variables (.env.development)
# Database Configuration
DATABASE_URL=postgresql://klerno_user:klerno_pass@localhost:5432/klerno_dev
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_CACHE_DB=1
REDIS_SESSION_DB=2

# Security Configuration
JWT_SECRET=supersecurekeythatislongerthan32charactersforjwtencryption12345
SECRET_KEY=anothersupersecretkeyforsessions12345678
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]

# Optimization Settings
ENABLE_PERFORMANCE_OPTIMIZATION=true
ENABLE_SECURITY_MONITORING=true
ENABLE_MEMORY_OPTIMIZATION=true
ENABLE_OBSERVABILITY=true

# Monitoring Configuration
OBSERVABILITY_SERVICE_NAME=klerno-dev
TRACING_SAMPLING_RATE=1.0
METRICS_COLLECTION_INTERVAL=10

# Cache Configuration
CACHE_DEFAULT_TTL=3600
CACHE_MAX_SIZE=1000
ENABLE_CACHE_COMPRESSION=false

# Alert Configuration
ALERT_WEBHOOK_URL=http://localhost:8001/alerts
ENABLE_EMAIL_ALERTS=false
ENABLE_SLACK_ALERTS=false
```

### Staging Environment

```bash
# Environment variables (.env.staging)
# Database Configuration
DATABASE_URL=postgresql://klerno_user:secure_password@staging-db:5432/klerno_staging
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30

# Redis Configuration
REDIS_URL=redis://staging-redis:6379/0
REDIS_CACHE_DB=1
REDIS_SESSION_DB=2

# Security Configuration
JWT_SECRET=${JWT_SECRET_STAGING}
SECRET_KEY=${SECRET_KEY_STAGING}
CORS_ORIGINS=["https://staging.klerno.com"]

# Optimization Settings
ENABLE_PERFORMANCE_OPTIMIZATION=true
ENABLE_SECURITY_MONITORING=true
ENABLE_MEMORY_OPTIMIZATION=true
ENABLE_OBSERVABILITY=true

# Monitoring Configuration
OBSERVABILITY_SERVICE_NAME=klerno-staging
TRACING_SAMPLING_RATE=0.1
METRICS_COLLECTION_INTERVAL=30

# Cache Configuration
CACHE_DEFAULT_TTL=7200
CACHE_MAX_SIZE=10000
ENABLE_CACHE_COMPRESSION=true

# Alert Configuration
ALERT_WEBHOOK_URL=https://hooks.slack.com/staging-alerts
ENABLE_EMAIL_ALERTS=true
ENABLE_SLACK_ALERTS=true
```

### Production Environment

```bash
# Environment variables (.env.production)
# Database Configuration
DATABASE_URL=postgresql://klerno_prod:${DB_PASSWORD}@prod-db-cluster:5432/klerno_production
DATABASE_POOL_SIZE=50
DATABASE_MAX_OVERFLOW=100

# Redis Configuration
REDIS_URL=redis://prod-redis-cluster:6379/0
REDIS_CACHE_DB=1
REDIS_SESSION_DB=2

# Security Configuration
JWT_SECRET=${JWT_SECRET_PRODUCTION}
SECRET_KEY=${SECRET_KEY_PRODUCTION}
CORS_ORIGINS=["https://klerno.com", "https://app.klerno.com"]

# Optimization Settings
ENABLE_PERFORMANCE_OPTIMIZATION=true
ENABLE_SECURITY_MONITORING=true
ENABLE_MEMORY_OPTIMIZATION=true
ENABLE_OBSERVABILITY=true

# Monitoring Configuration
OBSERVABILITY_SERVICE_NAME=klerno-production
TRACING_SAMPLING_RATE=0.05
METRICS_COLLECTION_INTERVAL=60

# Cache Configuration
CACHE_DEFAULT_TTL=3600
CACHE_MAX_SIZE=100000
ENABLE_CACHE_COMPRESSION=true

# Alert Configuration
ALERT_WEBHOOK_URL=https://hooks.slack.com/production-alerts
ENABLE_EMAIL_ALERTS=true
ENABLE_SLACK_ALERTS=true
ENABLE_PAGERDUTY_ALERTS=true

# Performance Settings
MAX_CONCURRENT_REQUESTS=1000
WORKER_PROCESSES=4
WORKER_CONNECTIONS=1000
```

## Docker Configuration

### Dockerfile

```dockerfile
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PATH="/opt/venv/bin:$PATH"

# Create virtual environment
RUN python -m venv /opt/venv

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Set work directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN groupadd -r klerno && useradd -r -g klerno klerno
RUN chown -R klerno:klerno /app
USER klerno

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Start command
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose - Development

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://klerno_user:klerno_pass@db:5432/klerno_dev
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - .:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: klerno_dev
      POSTGRES_USER: klerno_user
      POSTGRES_PASSWORD: klerno_pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  monitoring:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_data:
  redis_data:
  grafana_data:
```

### Docker Compose - Production

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  app:
    image: klerno/app:latest
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
      - SECRET_KEY=${SECRET_KEY}
    depends_on:
      - db
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

## Application Integration

### Main Application Setup

```python
# app/main.py - Updated with all optimizations
from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from contextlib import asynccontextmanager
import logging
import time

# Import all optimization modules
from enhanced_performance_optimization import performance_optimizer
from performance_optimization_endpoints import performance_router
from enhanced_api_documentation import setup_enhanced_documentation
from api_documentation_endpoints import documentation_router
from advanced_security_monitoring import security_monitor
from security_monitoring_endpoints import security_router
from enhanced_error_recovery import resilience_orchestrator
from enhanced_resilience_endpoints import resilience_router
from advanced_memory_optimization import memory_optimizer
from memory_optimization_endpoints import memory_router
from comprehensive_observability import observability
from observability_endpoints import observability_router

# Import existing app modules
from app.auth import router as auth_router
from app.admin import router as admin_router
from app.paywall import router as paywall_router
from app.guardian import router as guardian_router
from app.compliance import router as compliance_router
from app.settings import get_settings

settings = get_settings()
logger = logging.getLogger("klerno.main")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management with optimization startup."""
    
    # Startup - Initialize all optimization systems
    logger.info("üöÄ Starting Klerno Labs with Enterprise Optimizations")
    
    # Initialize performance optimization
    await performance_optimizer.initialize()
    performance_optimizer.start_monitoring()
    logger.info("‚úÖ Performance optimization initialized")
    
    # Initialize security monitoring
    security_monitor.start_monitoring()
    logger.info("‚úÖ Security monitoring initialized")
    
    # Initialize resilience system
    resilience_orchestrator.start_monitoring()
    logger.info("‚úÖ Resilience system initialized")
    
    # Initialize memory optimization
    memory_optimizer.start_monitoring()
    logger.info("‚úÖ Memory optimization initialized")
    
    # Initialize observability
    observability.start_monitoring()
    logger.info("‚úÖ Observability system initialized")
    
    # Setup health checks
    setup_health_checks()
    logger.info("‚úÖ Health checks configured")
    
    # Setup business metrics
    setup_business_metrics()
    logger.info("‚úÖ Business metrics configured")
    
    logger.info("üéØ All enterprise optimizations active - System ready!")
    
    yield
    
    # Shutdown
    logger.info("üîÑ Shutting down optimization systems")


def setup_health_checks():
    """Setup comprehensive health checks."""
    
    def check_database():
        # Implement database health check
        try:
            # Your database health check logic
            return True
        except:
            return False
    
    def check_redis():
        # Implement Redis health check
        try:
            # Your Redis health check logic
            return True
        except:
            return False
    
    def check_external_apis():
        # Check external API dependencies
        try:
            # Your external API health checks
            return True
        except:
            return False
    
    # Register health checks with observability system
    observability.add_health_check("database", check_database)
    observability.add_health_check("redis", check_redis)
    observability.add_health_check("external_apis", check_external_apis)


def setup_business_metrics():
    """Setup business-specific metrics."""
    from comprehensive_observability import MetricType
    
    # Define business metrics
    business_metrics = [
        ("business.users.active", MetricType.GAUGE, "Active users count"),
        ("business.revenue.daily", MetricType.GAUGE, "Daily revenue", "dollars"),
        ("business.orders.created", MetricType.COUNTER, "Orders created"),
        ("business.api.requests", MetricType.COUNTER, "API requests"),
        ("business.errors.rate", MetricType.GAUGE, "Error rate", "percent"),
        ("business.response.time", MetricType.HISTOGRAM, "Response time", "milliseconds")
    ]
    
    for name, metric_type, description, unit in business_metrics:
        observability.metrics.define_metric(name, metric_type, description, unit)


# Create FastAPI application with optimizations
app = FastAPI(
    title="Klerno Labs - Enterprise Platform",
    description="Enterprise-grade financial compliance and blockchain analysis platform with comprehensive optimizations",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add middleware in correct order
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add optimization middleware
@app.middleware("http")
async def optimization_middleware(request: Request, call_next):
    """Comprehensive optimization middleware."""
    start_time = time.time()
    
    # Start distributed trace
    span = observability.tracer.start_span(
        f"{request.method} {request.url.path}",
        tags={
            "http.method": request.method,
            "http.url": str(request.url),
            "service.name": "klerno-api"
        }
    )
    
    try:
        # Security monitoring
        security_check = await security_monitor.analyze_request(request)
        if security_check.get("block_request"):
            span.add_tag("security.blocked", True)
            observability.tracer.finish_span(span)
            return Response(status_code=403, content="Request blocked by security monitoring")
        
        # Process request
        response = await call_next(request)
        
        # Record metrics
        duration_ms = (time.time() - start_time) * 1000
        
        observability.metrics.record_histogram(
            "business.response.time",
            duration_ms,
            tags={
                "method": request.method,
                "endpoint": request.url.path,
                "status": str(response.status_code)
            }
        )
        
        observability.metrics.increment_counter(
            "business.api.requests",
            tags={
                "method": request.method,
                "endpoint": request.url.path,
                "status": str(response.status_code)
            }
        )
        
        # Add response headers
        response.headers["X-Response-Time"] = f"{duration_ms:.2f}ms"
        response.headers["X-Klerno-Version"] = "2.0.0"
        
        # Finish trace
        span.add_tag("http.status_code", response.status_code)
        span.add_tag("response.time_ms", duration_ms)
        observability.tracer.finish_span(span)
        
        return response
        
    except Exception as e:
        # Record error metrics
        duration_ms = (time.time() - start_time) * 1000
        
        observability.metrics.increment_counter(
            "business.errors.rate",
            tags={
                "method": request.method,
                "endpoint": request.url.path,
                "error_type": type(e).__name__
            }
        )
        
        # Finish trace with error
        span.add_tag("error", True)
        span.add_log("error", str(e))
        observability.tracer.finish_span(span, error=e)
        
        raise


# Include all routers
# Optimization system routers
app.include_router(performance_router, prefix="/api/v1")
app.include_router(documentation_router, prefix="/api/v1")
app.include_router(security_router, prefix="/api/v1")
app.include_router(resilience_router, prefix="/api/v1")
app.include_router(memory_router, prefix="/api/v1")
app.include_router(observability_router, prefix="/api/v1")

# Application routers
app.include_router(auth_router, prefix="/api/v1")
app.include_router(admin_router, prefix="/api/v1")
app.include_router(paywall_router, prefix="/api/v1")
app.include_router(guardian_router, prefix="/api/v1")
app.include_router(compliance_router, prefix="/api/v1")

# Setup enhanced API documentation
setup_enhanced_documentation(app)

# Root endpoints
@app.get("/")
async def root():
    """Root endpoint with system status."""
    return {
        "message": "Klerno Labs - Enterprise Platform",
        "version": "2.0.0",
        "status": "operational",
        "optimizations": [
            "performance",
            "security",
            "resilience", 
            "memory",
            "observability"
        ],
        "documentation": "/docs",
        "api_status": "/api/v1/status"
    }

@app.get("/health")
async def health_check():
    """Comprehensive health check endpoint."""
    health_status = {}
    
    # Check all optimization systems
    try:
        # Performance system health
        perf_metrics = performance_optimizer.get_comprehensive_metrics()
        health_status["performance"] = {
            "status": "healthy",
            "optimization_active": True,
            "cache_hit_rate": perf_metrics.get("cache", {}).get("hit_rate", 0)
        }
    except Exception as e:
        health_status["performance"] = {"status": "error", "error": str(e)}
    
    try:
        # Security system health
        security_metrics = security_monitor.get_comprehensive_metrics()
        health_status["security"] = {
            "status": "healthy",
            "monitoring_active": True,
            "threats_detected": security_metrics.get("total_threats_detected", 0)
        }
    except Exception as e:
        health_status["security"] = {"status": "error", "error": str(e)}
    
    try:
        # Memory system health
        memory_metrics = memory_optimizer.get_comprehensive_metrics()
        health_status["memory"] = {
            "status": "healthy",
            "optimization_active": True,
            "memory_pressure": memory_metrics.get("memory_pressure", "unknown")
        }
    except Exception as e:
        health_status["memory"] = {"status": "error", "error": str(e)}
    
    try:
        # Observability system health
        obs_status = observability.get_comprehensive_status()
        health_status["observability"] = {
            "status": "healthy",
            "tracing_active": obs_status.get("tracing", {}).get("active_spans", 0) >= 0,
            "metrics_active": obs_status.get("metrics", {}).get("active_metrics", 0) >= 0
        }
    except Exception as e:
        health_status["observability"] = {"status": "error", "error": str(e)}
    
    # Overall status
    all_healthy = all(
        status.get("status") == "healthy" 
        for status in health_status.values()
    )
    
    return {
        "status": "healthy" if all_healthy else "degraded",
        "timestamp": time.time(),
        "systems": health_status,
        "version": "2.0.0"
    }

@app.get("/api/v1/status")
async def api_status():
    """Comprehensive API status with all optimization metrics."""
    try:
        return {
            "api_version": "v1",
            "system_version": "2.0.0",
            "status": "operational",
            "optimizations": {
                "performance": performance_optimizer.get_comprehensive_metrics(),
                "security": security_monitor.get_comprehensive_metrics(),
                "resilience": resilience_orchestrator.get_comprehensive_metrics(),
                "memory": memory_optimizer.get_comprehensive_metrics(),
                "observability": observability.get_comprehensive_status()
            },
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Error getting API status: {e}")
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
```

## Kubernetes Deployment

### Kubernetes Manifests

```yaml
# k8s/namespace.yml
apiVersion: v1
kind: Namespace
metadata:
  name: klerno-production

---
# k8s/configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: klerno-config
  namespace: klerno-production
data:
  OBSERVABILITY_SERVICE_NAME: "klerno-production"
  TRACING_SAMPLING_RATE: "0.05"
  METRICS_COLLECTION_INTERVAL: "60"
  CACHE_DEFAULT_TTL: "3600"
  ENABLE_PERFORMANCE_OPTIMIZATION: "true"
  ENABLE_SECURITY_MONITORING: "true"
  ENABLE_MEMORY_OPTIMIZATION: "true"
  ENABLE_OBSERVABILITY: "true"

---
# k8s/secret.yml
apiVersion: v1
kind: Secret
metadata:
  name: klerno-secrets
  namespace: klerno-production
type: Opaque
data:
  DATABASE_URL: <base64-encoded-db-url>
  JWT_SECRET: <base64-encoded-jwt-secret>
  SECRET_KEY: <base64-encoded-secret-key>

---
# k8s/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: klerno-app
  namespace: klerno-production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: klerno-app
  template:
    metadata:
      labels:
        app: klerno-app
    spec:
      containers:
      - name: klerno-app
        image: klerno/app:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: klerno-secrets
              key: DATABASE_URL
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: klerno-secrets
              key: JWT_SECRET
        envFrom:
        - configMapRef:
            name: klerno-config
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/service.yml
apiVersion: v1
kind: Service
metadata:
  name: klerno-service
  namespace: klerno-production
spec:
  selector:
    app: klerno-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
# k8s/ingress.yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: klerno-ingress
  namespace: klerno-production
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.klerno.com
    secretName: klerno-tls
  rules:
  - host: api.klerno.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: klerno-service
            port:
              number: 80

---
# k8s/hpa.yml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: klerno-hpa
  namespace: klerno-production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: klerno-app
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## Deployment Scripts

### Deployment Script

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-development}
VERSION=${2:-latest}

echo "üöÄ Deploying Klerno Labs v${VERSION} to ${ENVIRONMENT}"

# Load environment-specific configuration
case $ENVIRONMENT in
  "development")
    ENV_FILE=".env.development"
    COMPOSE_FILE="docker-compose.dev.yml"
    ;;
  "staging")
    ENV_FILE=".env.staging"
    COMPOSE_FILE="docker-compose.staging.yml"
    ;;
  "production")
    ENV_FILE=".env.production"
    COMPOSE_FILE="docker-compose.prod.yml"
    ;;
  *)
    echo "‚ùå Invalid environment: $ENVIRONMENT"
    exit 1
    ;;
esac

# Verify environment file exists
if [ ! -f "$ENV_FILE" ]; then
    echo "‚ùå Environment file $ENV_FILE not found"
    exit 1
fi

echo "üìù Using configuration: $ENV_FILE"

# Build and tag images
echo "üî® Building application image..."
docker build -t klerno/app:${VERSION} .
docker tag klerno/app:${VERSION} klerno/app:latest

# Run database migrations
echo "üìä Running database migrations..."
docker-compose -f $COMPOSE_FILE --env-file $ENV_FILE run --rm app python -m alembic upgrade head

# Deploy application
echo "üöÄ Deploying application..."
docker-compose -f $COMPOSE_FILE --env-file $ENV_FILE up -d

# Wait for health check
echo "üè• Waiting for health check..."
for i in {1..30}; do
    if curl -f http://localhost:8000/health > /dev/null 2>&1; then
        echo "‚úÖ Application is healthy"
        break
    fi
    echo "‚è≥ Waiting for application to start... (attempt $i/30)"
    sleep 10
done

# Verify deployment
echo "üîç Verifying deployment..."
curl -s http://localhost:8000/api/v1/status | jq '.'

echo "‚úÖ Deployment complete! Application is running at http://localhost:8000"
echo "üìä Monitoring dashboard: http://localhost:3000"
echo "üìö API Documentation: http://localhost:8000/docs"
```

### Kubernetes Deployment Script

```bash
#!/bin/bash
# scripts/deploy-k8s.sh

set -e

ENVIRONMENT=${1:-production}
VERSION=${2:-latest}

echo "üöÄ Deploying Klerno Labs v${VERSION} to Kubernetes (${ENVIRONMENT})"

# Build and push image
echo "üî® Building and pushing Docker image..."
docker build -t klerno/app:${VERSION} .
docker tag klerno/app:${VERSION} klerno/app:latest
docker push klerno/app:${VERSION}
docker push klerno/app:latest

# Apply Kubernetes manifests
echo "üì¶ Applying Kubernetes manifests..."
kubectl apply -f k8s/namespace.yml
kubectl apply -f k8s/configmap.yml
kubectl apply -f k8s/secret.yml
kubectl apply -f k8s/deployment.yml
kubectl apply -f k8s/service.yml
kubectl apply -f k8s/ingress.yml
kubectl apply -f k8s/hpa.yml

# Wait for rollout
echo "‚è≥ Waiting for deployment rollout..."
kubectl rollout status deployment/klerno-app -n klerno-production --timeout=300s

# Verify deployment
echo "üîç Verifying deployment..."
kubectl get pods -n klerno-production
kubectl get services -n klerno-production
kubectl get ingress -n klerno-production

echo "‚úÖ Kubernetes deployment complete!"
echo "üåê Application URL: https://api.klerno.com"
echo "üìä Monitoring: kubectl port-forward -n klerno-production svc/grafana 3000:3000"
```

## Monitoring Setup

### Prometheus Configuration

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'klerno-app'
    static_configs:
      - targets: ['app:8000']
    metrics_path: '/api/v1/observability/metrics/prometheus'
    scrape_interval: 30s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
```

### Grafana Dashboard Configuration

```json
{
  "dashboard": {
    "title": "Klerno Labs - Enterprise Monitoring",
    "panels": [
      {
        "title": "System Health Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"klerno-app\"}",
            "legendFormat": "App Status"
          }
        ]
      },
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(business_api_requests_total[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(business_response_time_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "system_memory_usage",
            "legendFormat": "Memory %"
          }
        ]
      },
      {
        "title": "Cache Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "cache_hit_rate",
            "legendFormat": "Hit Rate %"
          }
        ]
      }
    ]
  }
}
```

## Security Configuration

### SSL/TLS Setup

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream klerno_app {
        server app:8000;
    }

    server {
        listen 443 ssl http2;
        server_name api.klerno.com;

        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
        ssl_prefer_server_ciphers off;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self'" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        location / {
            proxy_pass http://klerno_app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }

    server {
        listen 80;
        server_name api.klerno.com;
        return 301 https://$server_name$request_uri;
    }
}
```

## Performance Optimization

### Production Optimizations

```python
# config/production.py
import os

# Performance settings
UVICORN_WORKERS = int(os.getenv("UVICORN_WORKERS", 4))
UVICORN_WORKER_CONNECTIONS = int(os.getenv("UVICORN_WORKER_CONNECTIONS", 1000))
UVICORN_KEEPALIVE = int(os.getenv("UVICORN_KEEPALIVE", 2))

# Database optimization
DATABASE_POOL_SIZE = int(os.getenv("DATABASE_POOL_SIZE", 50))
DATABASE_MAX_OVERFLOW = int(os.getenv("DATABASE_MAX_OVERFLOW", 100))
DATABASE_POOL_PRE_PING = True
DATABASE_POOL_RECYCLE = 3600

# Cache optimization
CACHE_MAX_SIZE = int(os.getenv("CACHE_MAX_SIZE", 100000))
CACHE_DEFAULT_TTL = int(os.getenv("CACHE_DEFAULT_TTL", 3600))
ENABLE_CACHE_COMPRESSION = True

# Memory optimization
MEMORY_OPTIMIZATION_ENABLED = True
GC_OPTIMIZATION_ENABLED = True
MEMORY_POOL_SIZE = 100

# Security settings
SECURITY_MONITORING_ENABLED = True
THREAT_DETECTION_ENABLED = True
RATE_LIMITING_ENABLED = True

# Observability settings
TRACING_ENABLED = True
METRICS_ENABLED = True
PROFILING_ENABLED = True
ALERT_ENABLED = True
```

## Troubleshooting Guide

### Common Issues and Solutions

#### High Memory Usage
```bash
# Check memory usage
kubectl top pods -n klerno-production

# Scale up if needed
kubectl scale deployment klerno-app --replicas=5 -n klerno-production

# Check memory optimization metrics
curl http://localhost:8000/api/v1/memory/metrics/comprehensive
```

#### High Response Times
```bash
# Check performance metrics
curl http://localhost:8000/api/v1/performance/metrics/comprehensive

# Check cache performance
curl http://localhost:8000/api/v1/memory/cache/list

# Enable profiling for analysis
curl -X POST http://localhost:8000/api/v1/observability/profiling/response-times/start
```

#### Security Alerts
```bash
# Check security status
curl http://localhost:8000/api/v1/security/status/comprehensive

# Review active threats
curl http://localhost:8000/api/v1/security/threats/active

# Review security metrics
curl http://localhost:8000/api/v1/security/metrics/summary
```

This comprehensive integration and deployment guide provides everything needed to deploy the enterprise-grade Klerno Labs system with all optimizations in any environment. The system is now ready for production deployment with complete monitoring, security, and optimization capabilities.